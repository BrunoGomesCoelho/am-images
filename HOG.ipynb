{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_datasets import read_data \n",
    "from read_datasets import DATA_PATH, ICMC_PATH, ORIGNAL_PATH\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "icmc_x, icmc_y = read_data(DATA_PATH + ICMC_PATH, size=(20, 10, 300, 200))\n",
    "original_x, original_y = read_data(DATA_PATH + ORIGNAL_PATH,\n",
    "                            size=(20, 10, 112,  92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hog(imgs, testing=False):\n",
    "    \"\"\" Applys HOG (Histogram of oriented gradients) to array of images\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs :  numpy.array \n",
    "            Contains the images\n",
    "    \n",
    "    testing : boolean\n",
    "            Weather or not to use less data (for testing purposes)\n",
    "            Also return a tuple, with the second element being the visualization \n",
    "                of the image\n",
    "    \"\"\"\n",
    "    if testing:\n",
    "        visualize = True\n",
    "        imgs = imgs[:1]\n",
    "    else:\n",
    "        visualize = False\n",
    "    \n",
    "    new_imgs = []\n",
    "    for img in imgs:\n",
    "        new_imgs.append(hog(img, visualize=visualize, feature_vector=True))\n",
    "        \n",
    "    return np.array(new_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(data_x, data_y, path):\n",
    "    full_data = pd.DataFrame(data_x)\n",
    "    full_data[\"target\"] = data_y\n",
    "    \n",
    "    # Split a large csv file into multiple small csvs\n",
    "    # We always split, even if the size is small, for cleaner code\n",
    "    for name, group in full_data.groupby(\"target\"):\n",
    "        group.to_csv(path.replace(\".csv\", f\"{name}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_RUN = True   # By default we do not re-generate all data\n",
    "DEBUG = False    # By default we do not show any debug info (plots and sizes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if RE_RUN:\n",
    "        # Regenerate all data\n",
    "        img_folders = [ICMC_PATH, ORIGNAL_PATH]\n",
    "        file_names = [\"icmc.csv\", \"original.csv\"]\n",
    "        sizes = [(20, 10, 300, 200), (20, 10, 112,  92)]\n",
    "        \n",
    "        for folder, file_name, size in zip(img_folders, file_names, sizes):\n",
    "            data_x, data_y = read_data(DATA_PATH + folder, size=size)\n",
    "            hog_data = apply_hog(data_x)\n",
    "            save_dataset(hog_data, data_y, DATA_PATH + file_name)\n",
    "    \n",
    "    elif DEBUG:\n",
    "        # Plot of a converted image:\n",
    "        original_x, original_y = read_data(DATA_PATH + ICMC_PATH,\n",
    "                                            size=(20, 10, 300,  200))\n",
    "        img, show_img = apply_hog(original_x, testing=True)[0]\n",
    "        plt.imshow(show_img, cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution of data\n",
    "        imgs = apply_hog(original_x)\n",
    "        \n",
    "        # Get random columns and describe them\n",
    "        cols = np.random.randint(0, high=len(imgs[0])-1, size=100)\n",
    "        pd.DataFrame(imgs).iloc[:, cols].describe().T[[\"min\", \"max\"]]\n",
    "        print(\"Therefore we don't need to standardize since the min/max\", \n",
    "              \"is already very close\")\n",
    "    \n",
    "        print(\"Size of a feature vector:\", img.shape)\n",
    "    \n",
    "    else:\n",
    "        print(\"We are not running anything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
